import os
import uuid
import random
import time
import re
from pathlib import Path
from typing import List, Dict, Any
from dotenv import load_dotenv
from unidecode import unidecode

from config.settings import logger, PRIMARY_MODEL, FALLBACK_MODEL, EMBEDDING_MODEL, MAX_OUTPUT_TOKENS, API_TIMEOUT, RAG_NUM_CHUNKS, SIMILARITY_THRESHOLD, GOOGLE_API_KEY, CURSOS_SPREADSHEET_ID
from config.constants import INTENT_EXAMPLES, GREETING_WORDS, information_emojis, greeting_emojis, warning_emojis, success_emojis, SHEET_COURSE_KEYWORDS, CALENDAR_INTENT_MAPPING, CALENDAR_MESSAGES
from models.openai_model import OpenAIModel, OpenAIEmbedding
from storage.vector_store import PostgreSQLVectorStore
from utils.date_utils import DateUtils
from handlers.intent_handler import (
    normalize_intent_examples,
    get_query_intent,
    handle_conversational_intent,
)
from handlers.courses_handler import handle_sheet_course_query
from handlers.calendar_handler import get_calendar_events
from handlers.faqs_handler import handle_faq_query
from services.calendar_service import CalendarService
from services.sheets_service import SheetsService
from services.session_service import session_service

load_dotenv()

class RAGSystem:
    def __init__(self):
        self.user_history = {}
        self.max_history_length = 5
        self.openai_api_key = os.getenv('OPENAI_API_KEY')
        if not self.openai_api_key:
            raise ValueError("Se requiere OPENAI_API_KEY para usar el sistema")
        self.primary_model_name = PRIMARY_MODEL
        self.fallback_model_name = FALLBACK_MODEL
        self.embedding_model_name = EMBEDDING_MODEL
        self.max_output_tokens = MAX_OUTPUT_TOKENS
        self.api_timeout = API_TIMEOUT
        self.similarity_threshold = SIMILARITY_THRESHOLD
        self.normalized_intent_examples = normalize_intent_examples(INTENT_EXAMPLES)
        logger.info("Ejemplos de intenciones normalizados para mejorar la clasificaci√≥n")
        self.model = OpenAIModel(
            model_name=self.primary_model_name,
            api_key=self.openai_api_key,
            timeout=self.api_timeout,
            max_output_tokens=self.max_output_tokens
        )
        self.embedding_model = OpenAIEmbedding(
            model_name=self.embedding_model_name,
            api_key=self.openai_api_key,
            timeout=self.api_timeout
        )
        # Inicializar vector store con PostgreSQL/pgvector
        self.vector_store = PostgreSQLVectorStore(
            threshold=self.similarity_threshold
        )
        
        # Log de configuraci√≥n
        logger.info("Vector store configurado con PostgreSQL/pgvector")
        logger.info(f"Umbral de similitud: {self.similarity_threshold}")
        self.date_utils = DateUtils()
        try:
            self.calendar_service = CalendarService()
            logger.info("Servicio de calendario inicializado correctamente")
        except Exception as e:
            logger.warning(f"No se pudo inicializar el servicio de calendario: {str(e)}")
            self.calendar_service = None
        try:
            self.sheets_service = SheetsService(api_key=GOOGLE_API_KEY) if GOOGLE_API_KEY else None
            self.CURSOS_SPREADSHEET_ID = CURSOS_SPREADSHEET_ID
        except Exception as e:
            logger.warning(f"No se pudo inicializar el servicio de Google Sheets: {str(e)}")
            self.sheets_service = None

    def normalize_query(self, query: str) -> str:
        """Normaliza la consulta eliminando tildes, signos de puntuaci√≥n y normalizando espacios."""
        normalized = query.lower().strip()
        normalized = unidecode(normalized)  # Eliminar tildes
        normalized = re.sub(r'[^\w\s]', '', normalized)  # Eliminar signos de puntuaci√≥n
        normalized = re.sub(r'\s+', ' ', normalized).strip()  # Normalizar espacios
        return normalized

    def process_query(self, query: str, user_id: str = None, user_name: str = None) -> Dict[str, Any]:
        if user_id is None:
            user_id = str(uuid.uuid4())
        query_original = query
        query_lower = query.lower().strip()
        
        # Determinar intenci√≥n - primero con keywords para evitar llamadas innecesarias a la API
        # Pasamos None como embedding_model para usar solo keywords en primera instancia
        intent, confidence = get_query_intent(query_original, None, self.normalized_intent_examples)
        
        # Si no se detect√≥ por keywords o la confianza es baja, usar enfoque basado en palabras clave espec√≠ficas
        if intent == 'desconocido' or confidence < 0.6:
            # Revisamos si es una pregunta de cortes√≠a com√∫n
            if any(keyword in query_lower for keyword in ['como estas', 'c√≥mo est√°s', 'como te va', 'todo bien']):
                intent = 'cortesia'
                confidence = 0.8
                logger.info(f"Intenci√≥n detectada por patrones espec√≠ficos: {intent} (confianza: {confidence:.2f})")
            # Revisamos si pregunta por la identidad
            elif any(keyword in query_lower for keyword in ['como te llamas', 'c√≥mo te llam√°s', 'tu nombre', 'quien eres']):
                intent = 'identidad'
                confidence = 0.8
                logger.info(f"Intenci√≥n detectada por patrones espec√≠ficos: {intent} (confianza: {confidence:.2f})")
            else:
                logger.info(f"Usando enfoque RAG est√°ndar para la consulta")
        else:
            logger.info(f"Intenci√≥n detectada por keywords: {intent} (confianza: {confidence:.2f})")
        
        # Delegar manejo de intenciones conversacionales al intent handler
        conversational = handle_conversational_intent(
            intent, confidence, query_original, user_name
        )
        if conversational:
            return conversational
            
        # Para consultas con baja confianza, no preguntar directamente sino tratar de responder
        # con el sistema RAG normal, dejando que el modelo interprete directamente
        
        # Preguntas Frecuentes (FAQs)
        faq_response = handle_faq_query(query_original)
        if faq_response:
            logger.info(f"Consulta respondida desde el manejador de FAQs")
            self.update_user_history(user_id, query_original, faq_response)
            return {
                "query": query_original, 
                "response": faq_response,
                "query_type": "faq",
                "relevant_chunks": [], 
                "sources": ["Preguntas Frecuentes"]
            }
        
        # Cursos (Google Sheets) - con soporte para contexto conversacional
        # Verificar PRIMERO si es una consulta relativa de cursos
        context = session_service.get_context_for_relative_query(user_id, query_original)
        
        # Si es una consulta relativa sobre cursos O contiene palabras clave de cursos O menciona un mes con contexto de cursos
        months_es = ['enero', 'febrero', 'marzo', 'abril', 'mayo', 'junio', 'julio', 'agosto', 'septiembre', 'octubre', 'noviembre', 'diciembre']
        mentions_month = any(month in query_lower for month in months_es)
        has_context_courses = context["query_type"] == "cursos"
        
        is_course_query = (
            any(keyword in query_lower for keyword in SHEET_COURSE_KEYWORDS) or 
            (context["is_relative"] and context["query_type"] == "cursos") or
            (mentions_month and has_context_courses)  # NUEVO: detectar meses con contexto de cursos
        )
        
        if self.sheets_service and is_course_query:
            if context["is_relative"] and context["resolved_month"]:
                # Es una consulta relativa con mes resuelto
                logger.info(f"Procesando consulta relativa de cursos: {context['explanation']}")
                
                # Modificar la consulta para incluir el mes resuelto
                modified_query = f"cursos {context['resolved_month']}"
                sheet_course_response = handle_sheet_course_query(
                    modified_query, self.sheets_service, self.CURSOS_SPREADSHEET_ID, self.date_utils
                )
                
                # Actualizar contexto con la nueva consulta
                session_service.update_session_context(
                    user_id, query_original, "cursos", context["resolved_month"]
                )
                
                if sheet_course_response:
                    # Personalizar la respuesta para indicar que se interpret√≥ la consulta relativa
                    response_with_context = f"üìÖ {context['explanation']}:\n\n{sheet_course_response}"
                    self.update_user_history(user_id, query_original, response_with_context)
                    return {
                        "query": query_original, "response": response_with_context,
                        "query_type": "info_cursos_relativa",
                        "relevant_chunks": [], "sources": [f"Google Sheet Cursos - {context['resolved_month']}"]
                    }
            
            # Consulta normal de cursos
            sheet_course_response = handle_sheet_course_query(
                query_original, self.sheets_service, self.CURSOS_SPREADSHEET_ID, self.date_utils
            )
            if sheet_course_response:
                # Detectar qu√© mes se consult√≥ para actualizar el contexto
                query_lower_for_month = query_original.lower()
                months_es = {
                    'enero': 'ENERO', 'febrero': 'FEBRERO', 'marzo': 'MARZO', 'abril': 'ABRIL',
                    'mayo': 'MAYO', 'junio': 'JUNIO', 'julio': 'JULIO', 'agosto': 'AGOSTO',
                    'septiembre': 'SEPTIEMBRE', 'octubre': 'OCTUBRE', 'noviembre': 'NOVIEMBRE', 'diciembre': 'DICIEMBRE'
                }
                
                detected_month = None
                for month_name, month_upper in months_es.items():
                    if month_name in query_lower_for_month:
                        detected_month = month_upper
                        break
                
                # Si no se detect√≥ un mes espec√≠fico, verificar referencias relativas
                if not detected_month:
                    if any(phrase in query_lower_for_month for phrase in ["mes que viene", "pr√≥ximo mes", "proximo mes", "siguiente mes"]):
                        # Obtener el mes siguiente
                        current_month = self.date_utils.get_today().month
                        next_month = current_month + 1 if current_month < 12 else 1
                        detected_month = list(months_es.values())[next_month - 1]
                    else:
                        # Usar el mes actual como fallback
                        detected_month = self.date_utils.get_current_month_name()
                
                # Actualizar contexto
                session_service.update_session_context(
                    user_id, query_original, "cursos", detected_month
                )
                
                self.update_user_history(user_id, query_original, sheet_course_response)
                return {
                    "query": query_original, "response": sheet_course_response,
                    "query_type": "info_cursos",
                    "relevant_chunks": [], "sources": [f"Google Sheet Cursos"]
                }
        # Calendario - con soporte para contexto conversacional
        # Verificar si es una consulta relativa de calendario O contiene palabras clave de calendario
        is_calendar_query = False
        calendar_intent = None
        
        # Si es una consulta relativa sobre calendario
        if context["is_relative"] and context["query_type"].startswith("calendario") and context["resolved_time_reference"]:
            is_calendar_query = True
            calendar_intent = context["calendar_intent"]  # Usar el intent anterior
            
            logger.info(f"Procesando consulta relativa de calendario: {context['explanation']}")
            
            # Crear consulta modificada con la referencia temporal resuelta
            modified_query = f"eventos {context['resolved_time_reference']}"
            calendar_response = get_calendar_events(self.calendar_service, calendar_intent)
            
            # Actualizar contexto con la nueva consulta
            session_service.update_session_context(
                user_id, query_original, f"calendario_{calendar_intent}", 
                calendar_intent=calendar_intent, 
                time_reference=context["resolved_time_reference"]
            )
            
            if calendar_response:
                # Personalizar la respuesta para indicar que se interpret√≥ la consulta relativa
                response_with_context = f"üìÖ {context['explanation']}:\n\n{calendar_response}"
                self.update_user_history(user_id, query_original, response_with_context)
                return {
                    "query": query_original, "response": response_with_context,
                    "query_type": f"calendario_{calendar_intent}_relativa",
                    "relevant_chunks": [], "sources": [f"Calendario Acad√©mico - {context['resolved_time_reference']}"]
                }
        
        # Consulta normal de calendario (detectar por palabras clave O mes con contexto de calendario)
        has_context_calendar = context["query_type"].startswith("calendario")
        
        if not is_calendar_query:
            # Detectar por palabras clave de calendario
            for intent, config in CALENDAR_INTENT_MAPPING.items():
                if any(keyword in query_lower for keyword in config['keywords']):
                    calendar_intent = intent
                    is_calendar_query = True
                    break
            
            # Tambi√©n detectar si menciona un mes con contexto de calendario
            if not is_calendar_query and mentions_month and has_context_calendar:
                is_calendar_query = True
                calendar_intent = context["calendar_intent"]  # Usar el intent del contexto anterior
                logger.info(f"Consulta de calendario detectada por mes con contexto: {calendar_intent}")
        
        if is_calendar_query and calendar_intent:
            calendar_response = get_calendar_events(self.calendar_service, calendar_intent)
            
            # Detectar referencia temporal para guardar en el contexto
            time_reference = None
            if "esta semana" in query_lower:
                time_reference = "esta semana"
            elif "este mes" in query_lower:
                time_reference = "este mes"
            elif "pr√≥ximos" in query_lower or "proximos" in query_lower:
                time_reference = "pr√≥ximos eventos"
            
            # Actualizar contexto
            session_service.update_session_context(
                user_id, query_original, f"calendario_{calendar_intent}",
                calendar_intent=calendar_intent,
                time_reference=time_reference
            )
            
            self.update_user_history(user_id, query_original, calendar_response)
            return {
                "query": query_original,
                "response": calendar_response,
                "query_type": f"calendario_{calendar_intent}",
                "relevant_chunks": [],
                "sources": ["Calendario Acad√©mico"]
            }
        # RAG cl√°sico
        relevant_chunks = self.retrieve_relevant_chunks(query_original, k=RAG_NUM_CHUNKS)
        sources = [chunk.get('filename', '') for chunk in relevant_chunks if chunk.get('filename')]
        context = '\n\n'.join(chunk.get('text', '') for chunk in relevant_chunks)
        if not context.strip():
            emoji = random.choice(information_emojis)
            return {
                "query": query_original,
                "response": f"{emoji} Lo siento, no encontr√© informaci√≥n espec√≠fica sobre esta consulta en mis documentos. Te sugiero escribir a alumnos@fmed.uba.ar para obtener la informaci√≥n precisa que necesitas.",
                "relevant_chunks": [],
                "sources": [],
                "query_type": "sin_informaci√≥n"
            }
        response = self.generate_response(query_original, context, sources)
        self.update_user_history(user_id, query_original, response)
        return {
            "query": query_original,
            "response": response,
            "relevant_chunks": relevant_chunks,
            "sources": sources,
            "query_type": "consulta_general"
        }

    def retrieve_relevant_chunks(self, query: str, k: int = 5) -> List[Dict]:
        query = query.strip()
        if not query:
            return []
            
        # Normalizar consulta
        query_lower = query.lower().strip()
        
        # Sistema de detecci√≥n de "consultas cr√≠ticas" basado en entidades clave
        # Define entidades cr√≠ticas que deben ser priorizadas (m√°s general que hardcodear solo denuncias)
        critical_entities = {
            'denuncia': {
                'keywords': ['denuncia', 'denunciar', 'denuncias'],
                'context_words': ['presentar', 'c√≥mo', 'como', 'donde', 'd√≥nde', 'procedimiento'],
                'article_patterns': ['art. 5', 'art√≠culo 5', 'art. 5¬∫', 'art√≠culo 5¬∫'],
                'priority': 0.95,  # Prioridad muy alta
                'secondary_priority': 0.80  # Prioridad para menciones secundarias
            },
            'regimen_disciplinario': {
                'keywords': ['r√©gimen disciplinario', 'regimen disciplinario', 'disciplina', 'sanci√≥n', 'sancion'],
                'context_words': ['suspensi√≥n', 'suspension', 'aplazo', 'falta', 'sumario'],
                'article_patterns': [],
                'priority': 0.90,
                'secondary_priority': 0.75
            },
            'regularidad': {
                'keywords': ['regularidad', 'regular', 'condiciones'],
                'context_words': ['alumno', 'estudiante', 'requisito', 'mantener', 'perder'],
                'article_patterns': [],
                'priority': 0.90,
                'secondary_priority': 0.75
            }
            # Se pueden a√±adir m√°s entidades cr√≠ticas aqu√≠ sin modificar la l√≥gica general
        }
        
        # Detectar si es una consulta sobre una entidad cr√≠tica
        detected_entities = []
        for entity_name, entity_data in critical_entities.items():
            # Verificar keywords principales
            if any(keyword in query_lower for keyword in entity_data['keywords']):
                # Si tambi√©n contiene palabras de contexto, es a√∫n m√°s relevante
                if any(context in query_lower for context in entity_data['context_words']):
                    detected_entities.append((entity_name, entity_data, True))  # True = alta prioridad
                else:
                    detected_entities.append((entity_name, entity_data, False))  # False = prioridad est√°ndar
        
        # Realizar b√∫squeda especializada para entidades cr√≠ticas detectadas
        priority_chunks = []
        if detected_entities:
            logger.info(f"Detectadas entidades cr√≠ticas: {[e[0] for e in detected_entities]}")
            
            # Buscar chunks relacionados con las entidades detectadas
            for entity_name, entity_data, is_high_priority in detected_entities:
                logger.info(f"Realizando b√∫squeda prioritaria para entidad: {entity_name}")
                
                # Buscar chunks que contengan informaci√≥n relevante sobre esta entidad
                # Nota: PostgreSQLVectorStore no tiene metadata_df, se usa b√∫squeda por embedding
                logger.info(f"B√∫squeda por embedding para entidad: {entity_name}")
                # La b√∫squeda se realizar√° por embedding en lugar de metadata_df
        
        # Realizar b√∫squeda principal por embedding
        query_embedding = self.embedding_model.encode([query])[0]
        results = self.vector_store.search(query_embedding, k=k)
        
        # A√±adir chunks prioritarios si se detectaron entidades cr√≠ticas
        if priority_chunks:
            # A√±adir solo chunks que no est√©n ya en los resultados
            for chunk in priority_chunks:
                if not any(r.get('text') == chunk.get('text') for r in results):
                    results.insert(0, chunk)  # Insertar al inicio para m√°xima prioridad
            
            # Limitar los resultados si exceden k+3
            if len(results) > k+3:
                results = results[:k+3]
                
            logger.info(f"Se agregaron {len(priority_chunks)} chunks prioritarios")
        
        # Extracci√≥n de palabras clave de la consulta
        important_keywords = self.extract_keywords_from_query(query_lower)
        logger.info(f"Palabras clave extra√≠das: {important_keywords}")
        
        # Si no hay suficientes resultados o la similitud es baja, intentar complementar con palabras clave
        if len(results) < 3 or (results and results[-1]['similarity'] < self.similarity_threshold + 0.05):
            logger.info(f"Resultados iniciales insuficientes, intentando complementar con palabras clave: {important_keywords}")
            
            # Intentar b√∫squedas adicionales solo con las palabras clave m√°s importantes
            for keyword in important_keywords[:3]:  # Usar solo las 3 palabras clave m√°s importantes
                # Buscar chunks que contengan esta palabra clave usando b√∫squeda por embedding
                logger.info(f"B√∫squeda adicional por palabra clave: {keyword}")
                # Nota: PostgreSQLVectorStore no tiene metadata_df, se usa b√∫squeda por embedding
                # La b√∫squeda se realizar√° por embedding en lugar de metadata_df
        
        # Log de resultados encontrados
        logger.info(f"N√∫mero total de chunks recuperados: {len(results)}")
        for i, r in enumerate(results):
            filename = r.get('filename', 'unknown')
            similarity = r.get('similarity', 0)
            text_preview = r.get('text', '')[:100] + '...' if len(r.get('text', '')) > 100 else r.get('text', '')
            logger.info(f"Chunk {i+1}: {filename} (similitud: {similarity:.2f}) - {text_preview}")
        
        # Ordenar por similitud para mantener los mejores resultados primero
        results = sorted(results, key=lambda x: x.get('similarity', 0), reverse=True)
        
        # Limitar al n√∫mero m√°ximo de resultados
        results = results[:k+3]  # Permitir hasta 3 resultados adicionales
        
        return results
        
    def extract_keywords_from_query(self, query: str) -> List[str]:
        """
        Extrae palabras clave relevantes de la consulta.
        
        Args:
            query (str): Consulta normalizada
            
        Returns:
            List[str]: Lista de palabras clave ordenadas por relevancia
        """
        # Limpieza adicional para eliminar signos de puntuaci√≥n
        query = re.sub(r'[^\w\s]', ' ', query).strip()
        
        # Palabras comunes en espa√±ol a ignorar
        stopwords = ['el', 'la', 'los', 'las', 'un', 'una', 'unos', 'unas', 'es', 'son', 'y', 'o', 
                   'a', 'ante', 'bajo', 'con', 'contra', 'de', 'desde', 'en', 'entre', 'hacia', 
                   'hasta', 'para', 'por', 'segun', 'sin', 'sobre', 'tras', 'como', 'que', 'quien',
                   'donde', 'cuando', 'cuanto', 'cual', 'cuales', 'cuantos', 'cuantas', 'me', 'mi',
                   'tu', 'te', 'se', 'nos', 'le', 'lo', 'su', 'sus', 'esto', 'eso', 'aquello', 'este',
                   'ese', 'aquel', 'esta', 'esa', 'aquella', 'estos', 'esos', 'aquellos', 'estas', 
                   'esas', 'aquellas']
        
        # Dividir en palabras
        words = query.split()
        
        # Filtrar stopwords y palabras cortas
        keywords = [word for word in words if word not in stopwords and len(word) > 2]
        
        # Definir palabras clave del dominio por categor√≠as
        domain_keywords = {
            # T√©rminos relacionados con normativas y reglamentos
            'normativas': {
                'weight': 10,
                'terms': ['regimen', 'disciplinario', 'reglamento', 'normativa', 'articulo', 
                          'resoluci√≥n', 'regulaci√≥n', 'estatuto', 'disposici√≥n']
            },
            # T√©rminos relacionados con denuncias y tr√°mites
            'denuncias': {
                'weight': 15,
                'terms': ['denuncia', 'denuncias', 'denunciar', 'presentar', 'tramitar', 
                          'procedimiento', 'formular']
            },
            # T√©rminos relacionados con la condici√≥n de estudiante
            'condicion_estudiante': {
                'weight': 10,
                'terms': ['regularidad', 'regular', 'condicion', 'condiciones', 'alumno', 
                          'estudiante', 'readmision', 'reincorporacion']
            },
            # T√©rminos relacionados con cursadas y materias
            'cursada': {
                'weight': 9,
                'terms': ['materias', 'asignaturas', 'aprobadas', 'aprobar', 'inscripcion', 
                          'inscribirse', 'recursar', 'aplazo', 'aplazos']
            },
            # T√©rminos relacionados con sanciones
            'sanciones': {
                'weight': 10,
                'terms': ['sancion', 'sanciones', 'suspension', 'sumario', 'falta', 'faltas']
            },
            # T√©rminos de navegaci√≥n y b√∫squeda
            'navegacion': {
                'weight': 8,
                'terms': ['donde', 'd√≥nde', 'como', 'c√≥mo', 'manera', 'forma', 'cuando', 
                          'cu√°ndo', 'quien', 'qui√©n', 'requisitos']
            }
        }

        # Detectar patrones de preguntas espec√≠ficas sobre procedimientos
        procedure_patterns = [
            # Patrones para "c√≥mo hacer algo"
            r'(como|c√≥mo).*?(hacer|presentar|realizar|tramitar|inscribir)',
            # Patrones para "d√≥nde hacer algo"
            r'(donde|d√≥nde).*?(presentar|ir|entregar|solicitar|tramitar)',
            # Patrones para "cu√°l es el procedimiento"
            r'(cual|cu√°l).*?(procedimiento|forma|tr√°mite|proceso)',
            # Patrones para "qu√© necesito para"
            r'(que|qu√©).*?(necesito|requiero|debo).*?(para|hacer)',
            # Patrones gen√©ricos de solicitud
            r'(quiero|deseo|necesito).*?(hacer|presentar|solicitar|tramitar)'
        ]
        
        # Detectar si es una consulta sobre alg√∫n procedimiento
        is_procedure_query = False
        for pattern in procedure_patterns:
            if re.search(pattern, query.lower()):
                is_procedure_query = True
                logger.info(f"Detectado patr√≥n de procedimiento: {pattern}")
                break
        
        # Asignar pesos a las palabras clave seg√∫n su categor√≠a
        weighted_keywords = []
        for word in keywords:
            weight_assigned = False
            
            # Buscar en cada categor√≠a
            for category, data in domain_keywords.items():
                if word in data['terms']:
                    # Si es pregunta de procedimiento, dar m√°s peso a palabras de procedimientos
                    extra_weight = 5 if is_procedure_query and category in ['denuncias', 'navegacion'] else 0
                    weighted_keywords.append((word, data['weight'] + extra_weight))
                    weight_assigned = True
                    break
            
            # Si no se encontr√≥ en ninguna categor√≠a, asignar peso predeterminado
            if not weight_assigned:
                weighted_keywords.append((word, 5))
        
        # Ordenar por importancia
        weighted_keywords.sort(key=lambda x: x[1], reverse=True)
        
        # Asegurar que las palabras m√°s importantes est√©n bien representadas
        # Si no hay palabras clave del dominio pero se detecta un patr√≥n de procedimiento,
        # a√±adir "procedimiento" como palabra clave
        if is_procedure_query and not any(w[1] > 5 for w in weighted_keywords):
            weighted_keywords.insert(0, ('procedimiento', 10))
        
        # Devolver solo las palabras
        return [word for word, _ in weighted_keywords]

    def enhance_context(self, query: str, context: str) -> str:
        """
        Mejora el contexto para destacar la informaci√≥n m√°s relevante para la consulta.
        
        Args:
            query (str): Consulta del usuario
            context (str): Contexto recuperado del sistema RAG
            
        Returns:
            str: Contexto mejorado con informaci√≥n destacada
        """
        # Sistema de detecci√≥n de "tipos de consulta" para personalizar el contexto
        query_types = {
            'procedimiento': {
                'patterns': [
                    r'(como|c√≥mo).*?(hacer|presentar|realizar|obtener)',
                    r'(donde|d√≥nde).*?(presentar|hacer|obtener|solicitar)',
                    r'(cual|cu√°l).*?(procedimiento|forma|manera|paso)',
                ],
                'keywords': ['procedimiento', 'paso', 'requisito', 'tramitar', 'presentar', 'realizar'],
                'highlight': 'PROCEDIMIENTO:'
            },
            'normativa': {
                'patterns': [
                    r'(que|qu√©).*?(dice|establece|indica).*?(reglamento|normativa|r√©gimen)',
                    r'(art√≠culo|art).*?(\d+)',
                    r'(seg√∫n|segun).*?(reglamento|normativa|r√©gimen)',
                ],
                'keywords': ['reglamento', 'normativa', 'r√©gimen', 'disciplinario', 'art√≠culo', 'resoluci√≥n'],
                'highlight': 'NORMATIVA APLICABLE:'
            },
            'denuncia': {
                'patterns': [
                    r'(denuncia|denunciar|denuncias)',
                    r'(presentar|hacer).*?(denuncia|denuncias)',
                ],
                'keywords': ['denuncia', 'denunciar', 'denuncias'],
                'highlight': 'INFORMACI√ìN SOBRE DENUNCIAS:'
            },
            'regularidad': {
                'patterns': [
                    r'(regularidad|regular|condici√≥n|condicion).*?(alumno|estudiante)',
                    r'(perder|mantener|recuperar).*?(regularidad|condici√≥n|condicion)',
                ],
                'keywords': ['regularidad', 'regular', 'condici√≥n', 'estudiante', 'alumno'],
                'highlight': 'CONDICIONES DE REGULARIDAD:'
            }
        }
        
        # Detectar el tipo de consulta
        detected_types = []
        for query_type, data in query_types.items():
            # Verificar patrones
            for pattern in data['patterns']:
                if re.search(pattern, query.lower()):
                    detected_types.append(query_type)
                    logger.info(f"Detectado tipo de consulta: {query_type} (patr√≥n: {pattern})")
                    break
            
            # Si no se detect√≥ por patr√≥n, verificar keywords
            if query_type not in detected_types:
                if any(keyword in query.lower() for keyword in data['keywords']):
                    detected_types.append(query_type)
                    logger.info(f"Detectado tipo de consulta: {query_type} (keywords)")
        
        # Extraer palabras clave de la consulta
        keywords = self.extract_keywords_from_query(query.lower())
        
        # Dividir el contexto en p√°rrafos
        paragraphs = context.split('\n\n')
        
        # Identificar si la consulta busca informaci√≥n espec√≠fica sobre art√≠culos
        seeking_articles = any(word in query.lower() for word in ['articulo', 'art√≠culo', 'art', 'apartado', 'inciso', 'punto'])
        
        # Patrones para detectar referencias a art√≠culos
        article_patterns = [
            r'Art\. \d+[¬∫¬∞]?\.', 
            r'Art√≠culo \d+[¬∫¬∞]?\.', 
            r'Art√≠culo \d+[¬∫¬∞]?:', 
            r'Art\. \d+[¬∫¬∞]?:',
            r'inc\. [a-z]\)'
        ]
        
        # Para cada p√°rrafo, verificar si contiene informaci√≥n relevante
        enhanced_paragraphs = []
        for paragraph in paragraphs:
            relevance_score = 0
            
            # Verificar si el p√°rrafo contiene palabras clave de la consulta
            for keyword in keywords:
                if keyword in paragraph.lower():
                    relevance_score += 1
            
            # Verificar si el p√°rrafo menciona alg√∫n art√≠culo
            has_article = False
            specific_article = None
            for pattern in article_patterns:
                article_match = re.search(pattern, paragraph)
                if article_match:
                    has_article = True
                    relevance_score += 2
                    specific_article = article_match.group(0)
            
            # Si la consulta busca art√≠culos espec√≠ficamente, dar m√°s peso a p√°rrafos con art√≠culos
            if seeking_articles and has_article:
                relevance_score += 3
            
            # Dar m√°s peso a p√°rrafos relevantes para los tipos de consulta detectados
            for query_type in detected_types:
                if any(keyword in paragraph.lower() for keyword in query_types[query_type]['keywords']):
                    relevance_score += 3
                    
                    # Destacar especialmente este p√°rrafo con un prefijo
                    if relevance_score >= 5:
                        enhanced_paragraphs.append(f"{query_types[query_type]['highlight']}\n{paragraph}")
                        break
            else:  # Este else pertenece al for, se ejecuta si no hubo break
                # Destacar p√°rrafos muy relevantes
                if relevance_score >= 4:
                    enhanced_paragraphs.append(f"INFORMACI√ìN RELEVANTE:\n{paragraph}")
                elif relevance_score > 0:
                    enhanced_paragraphs.append(paragraph)
                elif has_article:  # Incluir todos los art√≠culos, incluso si no parecen directamente relevantes
                    enhanced_paragraphs.append(paragraph)
        
        # Si no hay p√°rrafos con relevancia, usar el contexto original
        if not enhanced_paragraphs:
            return context
            
        # Buscar art√≠culos espec√≠ficos importantes si no fueron incluidos
        # Esto es m√°s general que solo buscar el Art√≠culo 5 para denuncias
        for query_type in detected_types:
            if query_type in ['normativa', 'denuncia', 'regularidad'] and len(enhanced_paragraphs) < 5:
                for paragraph in paragraphs:
                    if paragraph not in enhanced_paragraphs:
                        # Buscar art√≠culos relevantes seg√∫n el tipo de consulta
                        relevant_keywords = query_types[query_type]['keywords']
                        if has_article and any(keyword in paragraph.lower() for keyword in relevant_keywords):
                            enhanced_paragraphs.append(paragraph)
                            break
            
        # Unir p√°rrafos destacados
        enhanced_context = '\n\n'.join(enhanced_paragraphs)
        
        # A√±adir un mensaje introductorio relevante seg√∫n el tipo de consulta
        intro_messages = {
            'procedimiento': "A continuaci√≥n se detalla el procedimiento seg√∫n la normativa oficial:",
            'normativa': "A continuaci√≥n se citan las disposiciones relevantes de la normativa:",
            'denuncia': "La siguiente informaci√≥n explica el procedimiento oficial para presentar denuncias:",
            'regularidad': "A continuaci√≥n se detallan las condiciones de regularidad seg√∫n la normativa vigente:"
        }
        
        if detected_types and any(intro_messages.get(t) for t in detected_types):
            # Usar el primer tipo detectado que tenga mensaje introductorio
            for t in detected_types:
                if t in intro_messages:
                    enhanced_context = f"{intro_messages[t]}\n\n{enhanced_context}"
                    break
        
        return enhanced_context

    def generate_response(self, query: str, context: str, sources: List[str] = None) -> str:
        emoji = random.choice(information_emojis)
        
        # Preparar la lista de fuentes
        sources_text = ""
        if sources and len(sources) > 0:
            unique_sources = list(set(sources))  # Eliminar duplicados
            sources_text = f"\nFUENTES CONSULTADAS:\n{', '.join(unique_sources)}"
        
        # Analizar el contexto y la consulta para dar mejor estructura a la respuesta
        context_improved = self.enhance_context(query, context)
        
        # Sistema de clasificaci√≥n de consultas para personalizar instrucciones al modelo
        query_classifiers = {
            'denuncias': {
                'keywords': ['denuncia', 'denunciar', 'denuncias'],
                'patterns': [
                    r'(como|c√≥mo|de que forma|donde|d√≥nde).*?(presentar?|hacer|poner|realizar|tramitar).*?(denuncia)',
                    r'(presentar?|hacer|poner|realizar|tramitar).*?(denuncia)',
                ],
                'instructions': """
INSTRUCCIONES PARA CONSULTAS SOBRE DENUNCIAS:
- Menciona EXPL√çCITAMENTE que las denuncias se presentan POR ESCRITO
- Indica claramente que debe incluir una relaci√≥n circunstanciada de hechos y personas
- Menciona la alternativa de presentaci√≥n verbal en casos de urgencia
- Indica que la denuncia verbal debe ratificarse por escrito dentro de las 48 horas
- Si hay art√≠culos relevantes en la informaci√≥n, c√≠talos textualmente
- Aseg√∫rate de mencionar que la Universidad puede iniciar sumarios de oficio
"""
            },
            'regimen_disciplinario': {
                'keywords': ['r√©gimen disciplinario', 'regimen disciplinario', 'disciplina', 'sanci√≥n', 'sancion'],
                'patterns': [
                    r'(sancion|sanci√≥n|castigo|pena|amonestacion|expulsi√≥n|suspension).*?(estudiante|alumno)',
                    r'(que|qu√©).*?(sancion|sanci√≥n|castigo|pena).*?(corresponde|aplica)',
                ],
                'instructions': """
INSTRUCCIONES PARA CONSULTAS SOBRE R√âGIMEN DISCIPLINARIO:
- Cita con precisi√≥n los art√≠culos relevantes del R√©gimen Disciplinario
- Incluye los tipos de sanciones que pueden aplicarse y su graduaci√≥n
- Menciona qu√© autoridades pueden aplicar cada tipo de sanci√≥n
- Si se mencionan plazos o procedimientos espec√≠ficos, dest√°calos claramente
- Explica claramente qu√© derechos tiene el estudiante en un proceso disciplinario
"""
            },
            'regularidad': {
                'keywords': ['regularidad', 'regular', 'condiciones'],
                'patterns': [
                    r'(como|c√≥mo).*?(mantener|conseguir|obtener|perder).*?(regularidad|condici√≥n|condicion)',
                    r'(requisito|requisitos).*?(alumno regular|regularidad|condici√≥n)',
                ],
                'instructions': """
INSTRUCCIONES PARA CONSULTAS SOBRE REGULARIDAD:
- Destaca claramente el n√∫mero m√≠nimo de materias a aprobar en cada per√≠odo
- Menciona el porcentaje m√°ximo de aplazos permitidos
- Explica los plazos establecidos para completar la carrera
- Si hay excepciones o situaciones especiales, menci√≥nalas
- Cita los art√≠culos espec√≠ficos sobre regularidad que sean relevantes
"""
            }
        }
        
        # Detectar tipo de consulta
        specific_instructions = ""
        for category, data in query_classifiers.items():
            # Verificar por keywords
            if any(keyword in query.lower() for keyword in data['keywords']):
                specific_instructions = data['instructions']
                break
                
            # Verificar por patrones m√°s complejos
            if not specific_instructions:
                for pattern in data['patterns']:
                    if re.search(pattern, query.lower()):
                        specific_instructions = data['instructions']
                        break
                        
        prompt = f"""
Sos DrCecim, un asistente virtual especializado de la Facultad de Medicina UBA. Tu tarea es proporcionar respuestas sobre administraci√≥n y tr√°mites de la facultad y deben ser breves, precisas y √∫tiles.

INFORMACI√ìN RELEVANTE:
{context_improved}
{sources_text}

CONSULTA ACTUAL: {query}
{specific_instructions}

RESPONDE SIGUIENDO ESTAS REGLAS:
1. S√© muy conciso y directo
2. Usa la informaci√≥n de los documentos oficiales proporcionados
3. Si hay art√≠culos, resoluciones o reglamentos espec√≠ficos, cita exactamente el n√∫mero y fuente 
4. No omitas informaci√≥n importante de los documentos relevantes
5. Si hay documentos espec√≠ficos, cita naturalmente su origen ("Seg√∫n el reglamento...")
6. NO uses formato Markdown ya que esto no se procesa correctamente en mensajer√≠a
7. Para enfatizar texto, usa MAY√öSCULAS o comillas
8. Usa vi√±etas con guiones (-) cuando sea √∫til para organizar informaci√≥n
9. Si la informaci√≥n est√° incompleta, sugiere contactar a @cecim.nemed por instagram
10. No inventes o asumas informaci√≥n que no est√© en los documentos
11. No hagas preguntas adicionales en tu respuesta
"""
        try:
            response = self.model.generate(prompt)
        except Exception as e:
            logger.error(f"Error al generar respuesta con el modelo primario: {str(e)}")
            try:
                # Intentar con el modelo de respaldo
                logger.info(f"Intentando con el modelo de respaldo: {self.fallback_model_name}")
                fallback_model = OpenAIModel(
                    model_name=self.fallback_model_name,
                    api_key=self.openai_api_key,
                    timeout=self.api_timeout,
                    max_output_tokens=self.max_output_tokens
                )
                response = fallback_model.generate(prompt)
            except Exception as e2:
                logger.error(f"Error tambi√©n con el modelo de respaldo: {str(e2)}")
                return f"{emoji} Lo siento, hubo un error al generar la respuesta. Por favor, intenta de nuevo o contacta a @cecim.nemed por instagram."
                
        # Limpiar formatos que no se procesan bien en mensajer√≠a
        response = re.sub(r'\*\*(.+?)\*\*', r'\1', response)
        response = re.sub(r'\*(.+?)\*', r'\1', response)
        response = re.sub(r'\_\_(.+?)\_\_', r'\1', response)
        response = re.sub(r'\_(.+?)\_', r'\1', response)
        
        # Agregar emoji si no tiene uno al inicio
        if not re.match(r'[\U0001F300-\U0001F6FF\U0001F900-\U0001F9FF\u2600-\u26FF\u2700-\u27BF]', response.strip()[0:1]):
            response = f"{emoji} {response}"
        
        # Comprobar la calidad de la respuesta para tipos espec√≠ficos de consultas
        for category, data in query_classifiers.items():
            if any(keyword in query.lower() for keyword in data['keywords']) or any(re.search(pattern, query.lower()) for pattern in data['patterns']):
                # Lista de comprobaciones espec√≠ficas para categor√≠as principales
                if category == 'denuncias' and "por escrito" not in response.lower():
                    logger.warning("La respuesta sobre denuncias no incluye informaci√≥n sobre presentaci√≥n por escrito")
                    response += "\n\nRECUERDA: Las denuncias DEBEN presentarse POR ESCRITO con todos los detalles relevantes."
                    
                elif category == 'regimen_disciplinario' and not any(keyword in response.lower() for keyword in ['apercibimiento', 'suspensi√≥n', 'sanci√≥n']):
                    logger.warning("La respuesta sobre r√©gimen disciplinario no menciona tipos de sanciones")
                    
                elif category == 'regularidad' and not any(term in response.lower() for term in ['materias', 'aprobar', 'porcentaje', 'plazo']):
                    logger.warning("La respuesta sobre regularidad no incluye informaci√≥n sobre requisitos clave")
            
        return response

    def update_user_history(self, user_id: str, query: str, response: str):
        if user_id not in self.user_history:
            self.user_history[user_id] = []
        self.user_history[user_id].append({
            "query": query,
            "response": response,
            "timestamp": time.time()
        })
        if len(self.user_history[user_id]) > self.max_history_length:
            self.user_history[user_id] = self.user_history[user_id][-self.max_history_length:] 