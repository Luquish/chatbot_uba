# Configuración de entorno
# Opciones: development (desarrollo local con ngrok) o production (servidor en la nube)
ENVIRONMENT=development

# Configuración de WhatsApp Business API
WHATSAPP_API_TOKEN=your_whatsapp_api_token  # Token de acceso de WhatsApp Business API
WHATSAPP_PHONE_NUMBER_ID=your_phone_number_id  # ID del número de WhatsApp Business
WHATSAPP_BUSINESS_ACCOUNT_ID=your_business_account_id  # ID de la cuenta de negocio
WHATSAPP_WEBHOOK_VERIFY_TOKEN=your_webhook_verify_token  # Token para verificar webhooks

# Configuración de pruebas
MY_PHONE_NUMBER=

# Configuración de almacenamiento vectorial (Pinecone)
# Obtén estas credenciales desde tu panel de Pinecone
PINECONE_API_KEY=tu_api_key_aquí
PINECONE_ENVIRONMENT=tu_environment
PINECONE_INDEX_NAME=uba-chatbot-embeddings

# Configuración del servidor
HOST=0.0.0.0
PORT=8000

# Configuración del modelo y embeddings
MODEL_PATH=models/finetuned_model  # Ruta al modelo fine-tuneado
EMBEDDINGS_DIR=data/embeddings  # Directorio para almacenar embeddings

# Configuración de modelos de Hugging Face
BASE_MODEL_NAME=mistralai/Mistral-7B-Instruct-v0.3  # Modelo principal a usar
FALLBACK_MODEL_NAME=TinyLlama/TinyLlama-1.1B-Chat-v1.0  # Modelo de respaldo si falla el principal
BASE_MODEL_PATH=models/finetuned_model  # Ruta donde se guarda el modelo fine-tuneado
EMBEDDING_MODEL=sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2  # Modelo para embeddings

# Configuración de LoRA para fine-tuning
LORA_R=16
LORA_ALPHA=32
LORA_DROPOUT=0.05
TARGET_MODULES=q_proj,k_proj,v_proj,o_proj

# Configuración de RAG
RAG_NUM_CHUNKS=3  # Número de chunks a recuperar en cada consulta
MAX_LENGTH=512  # Longitud máxima de respuesta
TEMPERATURE=0.7  # Temperatura para generación
TOP_P=0.9  # Top-p para sampling
TOP_K=50  # Top-k para sampling

# Configuración de hardware
DEVICE=auto  # Dispositivo para inferencia (auto, cuda, cpu, mps)
USE_8BIT=false  # Usar cuantización de 8 bits
USE_4BIT=false  # Usar cuantización de 4 bits

# Configuración de Glitch (para desarrollo)
GLITCH_PROJECT_URL=your_glitch_project_url  # URL de tu proyecto en Glitch

# Configuración de Hugging Face
HF_TOKEN=

# Configuración del entorno
USE_API=True  # True para usar API, False para intentar cargar modelo localmente primero
API_TIMEOUT=30  # Timeout en segundos para llamadas a la API